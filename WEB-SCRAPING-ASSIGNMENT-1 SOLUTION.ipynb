{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aabc939d",
   "metadata": {},
   "source": [
    "Que 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "\n",
    "!pip install requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae251e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "headers = soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31718f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = []\n",
    "\n",
    "for i in headers:\n",
    "    header_names.append(i.text.strip())\n",
    "    \n",
    "header_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b091474",
   "metadata": {},
   "outputs": [],
   "source": [
    "len (header_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "w_header = pd.DataFrame({})\n",
    "\n",
    "w_header['Wikipedia Headers'] = header_names\n",
    "\n",
    "w_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c187e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33dae2bc",
   "metadata": {},
   "source": [
    "Que 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182322de",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.imdb.com/chart/top/\")\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e85e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "name=soup.find_all('td',class_='titleColumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f3629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Movie_Title=[]\n",
    "\n",
    "for i in name:\n",
    "    Movie_Title.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Movie_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f35d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "\n",
    "Movie_Rating=[]\n",
    "\n",
    "for i in rating:\n",
    " Movie_Rating.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Movie_Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ccdf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=soup.find_all('span',class_=\"secondaryInfo\")\n",
    "\n",
    "Year_of_Release=[]\n",
    "\n",
    "for i in year:\n",
    " Year_of_Release.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Year_of_Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store scrapped data in dataframe\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Movie Title']= Movie_Title[:100]\n",
    "data['Rating']=Movie_Rating[:100]\n",
    "data['Year_of_Release']=Year_of_Release[:100]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a96c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9681e5c4",
   "metadata": {},
   "source": [
    "Que 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "page3 = requests.get(\"https://www.imdb.com/india/top-rated-indian-movies\")\n",
    "page3.content\n",
    "\n",
    "soup3 = BeautifulSoup(page3.content)\n",
    "soup3\n",
    "\n",
    "movies2 = soup3.find_all('td', class_ = \"titleColumn\")\n",
    "movies2\n",
    "\n",
    "indian_movie = []\n",
    "\n",
    "for y in movies2:\n",
    "    indian_movie.append(y.a.text)\n",
    "indian_movie\n",
    "\n",
    "rating1 = soup3.find_all('td', class_='ratingColumn imdbRating')\n",
    "\n",
    "rating1\n",
    "\n",
    "Indian_rating = []\n",
    "\n",
    "for r in rating1:\n",
    "    Indian_rating.append(r.text.replace('\\n', \"\"))\n",
    "\n",
    "Indian_rating\n",
    "\n",
    "year2 = soup3.find_all('span', class_=\"secondaryInfo\")\n",
    "\n",
    "year2\n",
    "\n",
    "release_y = []\n",
    "\n",
    "for re in year2:\n",
    "    release_y.append(re.text.replace('\\n', \"\"))\n",
    "release_y\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({})\n",
    "\n",
    "df1['Movie Name'] = indian_movie[:100]\n",
    "df1['IMDB Ratings'] = Indian_rating[:100]\n",
    "df1['Year of Release'] = release_y[:100]\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98981665",
   "metadata": {},
   "source": [
    "Que 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ff4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "\n",
    "new\n",
    "\n",
    "new.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(new.content)\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name=soup.find_all('p',class_ = \"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "\n",
    "Product_name=[]\n",
    "for i in product_name:\n",
    " Product_name.append(i.text)\n",
    "\n",
    "Product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the price of poduct\n",
    "product_price=soup.find_all('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "\n",
    "Product_price=[]\n",
    "\n",
    "for i in product_price:\n",
    " Product_price.append(i.text)\n",
    "\n",
    "Product_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ac13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the discount on products\n",
    "\n",
    "product_discount=soup.find_all('span',class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\")\n",
    "\n",
    "Product_discount=[]\n",
    "\n",
    "for i in product_discount:\n",
    " Product_discount.append(i.text)\n",
    "\n",
    "Product_discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data in DataFrame\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "df['Product_name']=Product_name\n",
    "\n",
    "df['Product_price']=Product_price\n",
    "\n",
    "df['Product_discount']=Product_discount\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849ec8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7938f586",
   "metadata": {},
   "source": [
    "Que 5 - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "def Top_Mens_Teams(url):\n",
    " page = requests.get(url)\n",
    " page.content\n",
    " soup = BeautifulSoup(page.content)\n",
    " soup\n",
    " table = soup.find(\"tbody\")\n",
    "\n",
    "#find teams\n",
    " team_name = table.find_all(\"span\",class_=\"u-hide-phablet\")[0:10]\n",
    " teams = []\n",
    " for i in team_name:\n",
    "        teams.append(i.text)\n",
    "#find matches\n",
    " match = table.find_all(\"td\",class_=\"table-body__cell u-center-text\")\n",
    " f_match = table.find(\"td\",class_=\"rankings-block__banner--matches\").text\n",
    " f_points = table.find(\"td\",class_=\"rankings-block__banner--points\").text\n",
    " matches = [f_match,f_points]\n",
    " for i in match:\n",
    "        matches.append(i.text)\n",
    " m_records = matches[0:20:2]\n",
    " m_points = matches[1:20:2]\n",
    "\n",
    "\n",
    "#ratings\n",
    " f_rating = table.find(\"td\",class_=\"rankings-block__banner--rating u-text-right\").text.replace('\\n','').strip()\n",
    " ratings = table.find_all(\"td\",class_=\"table-body__cell u-text-right rating\")[0:10]\n",
    " team_rating = [f_rating]\n",
    " for i in ratings:\n",
    "    team_rating.append(i.text)\n",
    "\n",
    " data = list(zip(teams,m_records,m_points,team_rating))\n",
    " import pandas as pd\n",
    " df = pd.DataFrame(data, columns = [\"Team Name\",\"Matches\",\"Points\",\"Ratings\"])\n",
    " return(df)\n",
    "Top_Mens_Teams(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675613c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d93f7b7e",
   "metadata": {},
   "source": [
    "Que 5 - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "\n",
    "def Top_Batsmen(url):\n",
    " page = requests.get(url)\n",
    " page.content\n",
    " soup = BeautifulSoup(page.content)\n",
    " table = soup.find(\"table\",class_=\"table rankings-table\")\n",
    " first_player = table.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    " first_team = table.find(\"div\",class_=\"rankings-block__banner--nationality\").text.replace('\\n','')\n",
    " first_rating = table.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "\n",
    "\n",
    "#players\n",
    " players = table.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    " player=[first_player]\n",
    " for i in players:\n",
    "        player.append(i.text.replace('\\n',' '))\n",
    "\n",
    "        \n",
    "#teams\n",
    " teams= table.find_all(\"span\",class_=\"table-body__logo-text\")[0:9]\n",
    " team = [first_team]\n",
    " for i in teams:\n",
    "        team.append(i.text)\n",
    "        \n",
    "        \n",
    "#Rating\n",
    " ratings = table.find_all(\"td\",class_=\"table-body__cell rating\")[0:9]\n",
    " rating = [first_rating]\n",
    " for i in ratings:\n",
    "        rating.append(i.text)\n",
    "\n",
    "        \n",
    "        \n",
    " data = list(zip(player,team,rating))\n",
    " import pandas as pd\n",
    " df = pd.DataFrame(data, columns = [\"Player Name\",\"Team\",\"Rating\"])\n",
    " return(df)\n",
    "\n",
    "Top_Batsmen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773077c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06ee19d9",
   "metadata": {},
   "source": [
    "Que 5 - c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fbf143",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "def Top_Bowler(url):\n",
    " page=requests.get(url)\n",
    " page.content\n",
    " soup=BeautifulSoup(page.content)\n",
    " table=soup.find('table',class_=\"table rankings-table\")\n",
    "\n",
    "\n",
    "#first_Bowler\n",
    " first_bowler=table.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    " first_rating=table.find('div',class_=\"rankings-block__banner--rating\").text\n",
    " first_team=table.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n',' ')\n",
    "\n",
    "\n",
    "#Bowler\n",
    " bowlers=table.find_all('td',class_=\"table-body__cell rankings-table__name name\")[0:10]\n",
    " Bowler=[first_bowler]\n",
    " for i in bowlers:\n",
    "        Bowler.append(i.text.replace('\\n',' '))\n",
    " \n",
    "\n",
    "#teams\n",
    " teams=table.find_all('span',class_=\"table-body__logo-text\")[0:10]\n",
    " Team=[first_team]\n",
    " for i in teams:\n",
    "        Team.append(i.text.replace('\\n',' '))\n",
    "\n",
    "#rating\n",
    " rating=table.find_all('td',class_=\"table-body__cell rating\")[0:10]\n",
    " Rating=[first_rating]\n",
    " for i in rating:\n",
    "        Rating.append(i.text)\n",
    "\n",
    "        \n",
    " data=list(zip(Bowler,Team,Rating))\n",
    "\n",
    " import pandas as pd\n",
    " df=pd.DataFrame(data,columns=['Bowler','Team','Rating'])\n",
    " return(df)\n",
    "\n",
    "Top_Bowler(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a2ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73444ea5",
   "metadata": {},
   "source": [
    "Que 6 - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e53de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "\n",
    "def Top_womens_teams(url):\n",
    " page=requests.get(url)\n",
    " soup=BeautifulSoup(page.content)\n",
    "\n",
    " table=soup.find('tbody')\n",
    "\n",
    " team=table.find_all('span',class_=\"u-hide-phablet\")[0:10]\n",
    " teams=[]\n",
    " for i in team:\n",
    "        teams.append(i.text)\n",
    "\n",
    "\n",
    " match1=table.find('td',class_=\"rankings-block__banner--matches\").text\n",
    " point1=table.find('td',class_=\"rankings-block__banner--points\").text\n",
    " matches=table.find_all('td',class_=\"table-body__cell u-center-text\")\n",
    "\n",
    " Number_of_matches=[match1,point1]\n",
    " for i in matches:\n",
    "    Number_of_matches.append(i.text)\n",
    "\n",
    " m_record=Number_of_matches[0:20:2]\n",
    " m_points=Number_of_matches[1:20:2]\n",
    "\n",
    "    \n",
    "    \n",
    "#rating\n",
    " f_rating=table.find('td',class_=\"rankings-block__banner--rating u-text-right\").text.replace('\\n',' ')\n",
    " rating=table.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    " Ratings=[f_rating]\n",
    " for i in rating:\n",
    "    Ratings.append(i.text)\n",
    "\n",
    " data=list(zip(teams,m_record,m_points,Ratings))\n",
    "\n",
    " import pandas as pd\n",
    " df=pd.DataFrame(data,columns=['Team Name','Matches','Points','Ratings'])\n",
    " return(df)\n",
    "\n",
    "\n",
    "Top_womens_teams(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c757ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7dfc539",
   "metadata": {},
   "source": [
    "Que 6 - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08192d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "\n",
    "def Top_womens_batsmen(url):\n",
    " page=requests.get(url)\n",
    " soup=BeautifulSoup(page.content)\n",
    "\n",
    " table=soup.find('table',class_=\"table rankings-table\")\n",
    " fw_player=table.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    " fw_team=table.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n',' ')\n",
    " fw_rating=table.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "\n",
    "\n",
    " w_batsmen=table.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    " women_batsmen=[fw_player]\n",
    " for i in w_batsmen:\n",
    "    women_batsmen.append(i.text.replace('\\n',' '))\n",
    "\n",
    "\n",
    " w_teams=table.find_all('span',class_=\"table-body__logo-text\")[0:10]\n",
    " women_team=[fw_team]\n",
    " for i in w_teams:\n",
    "    women_team.append(i.text)\n",
    "\n",
    "\n",
    " w_ratings=table.find_all('td',class_=\"table-body__cell rating\")[0:10]\n",
    " Player_rating=[fw_rating]\n",
    " for i in w_ratings:\n",
    "    Player_rating.append(i.text)\n",
    "\n",
    "\n",
    " data=list(zip(women_batsmen,women_team,Player_rating))\n",
    "\n",
    " import pandas as pd\n",
    " df=pd.DataFrame(data,columns=[\"women_batsmen\",\"Team\",\"Player_rating\"])\n",
    " return(df)\n",
    "\n",
    "Top_womens_batsmen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f21a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5c6fe45",
   "metadata": {},
   "source": [
    "Que 6 - c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf434788",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "def Women_allrounder(url):\n",
    " page=requests.get(url)\n",
    " page.content\n",
    " soup=BeautifulSoup(page.content)\n",
    "\n",
    " table=soup.find('table',class_=\"table rankings-table\")\n",
    " f_allrounder=table.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    " f_allrounder_team=table.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n',' ')\n",
    " f_allrounder_rating=table.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "\n",
    "\n",
    "#allrounders\n",
    " all_rounders=table.find_all('td',class_=\"table-body__cell rankings-table__name name\")[0:10]\n",
    " W_allrounders=[f_allrounder]\n",
    " for i in all_rounders:\n",
    "    W_allrounders.append(i.text.replace('\\n',' '))\n",
    "\n",
    "#allrounder teams\n",
    " all_rounder_team=table.find_all('span',class_=\"table-body__logo-text\")[0:10]\n",
    " w_allrounder_team=[f_allrounder_team]\n",
    " for i in all_rounder_team:\n",
    "        w_allrounder_team.append(i.text.replace('\\n',' '))\n",
    "\n",
    "\n",
    "#allrounder ratings\n",
    " all_rounder_rating=table.find_all('td',class_=\"table-body__cell rating\")[0:10]\n",
    " w_allrounder_rating=[f_allrounder_rating]\n",
    " for i in all_rounder_rating:\n",
    "        w_allrounder_rating.append(i.text)\n",
    "\n",
    " data=list(zip(W_allrounders,w_allrounder_team,w_allrounder_rating))\n",
    " import pandas as pd\n",
    " df=pd.DataFrame(data,columns=['W_allrounders','w_allrounder_team','w_allrounder_rating'])\n",
    " return(df)\n",
    "\n",
    "Women_allrounder(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aee4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "196d0170",
   "metadata": {},
   "source": [
    "Que 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://coreyms.com/\"\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "\n",
    "articles = soup.find_all('article')\n",
    "\n",
    "data = []\n",
    "for article in articles:\n",
    "    header = article.find(\"header\")\n",
    "    \n",
    "#title\n",
    "    title = header.find(\"h2\").text\n",
    "\n",
    "    \n",
    "#date\n",
    "    date = header.find(\"time\", class_=\"entry-time\").text\n",
    "    div_block = article.find(\"div\", class_=\"entry-content\")\n",
    "\n",
    "    \n",
    "#paragraph\n",
    "    paragraph_content = div_block.find(\"p\").text\n",
    "    try:\n",
    "        youtube_link = div_block.find(\"iframe\", class_=\"youtube-player\")['src']\n",
    "        video_code = youtube_link.split(\"?\")[0].split(\"/\")[-1]\n",
    "    except:\n",
    "        video_code = \"NA\"\n",
    "    \n",
    "\n",
    "#video Code\n",
    "    data.append([title,date, paragraph_content, video_code])\n",
    "    \n",
    "#creating the dataframe\n",
    "columns = [\"Title\",\"Date\", \"Content\",\"Video Code\"]\n",
    "data = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b7ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92e46798",
   "metadata": {},
   "source": [
    "Que 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0260005",
   "metadata": {},
   "outputs": [],
   "source": [
    "page10 = requests.get(\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\")\n",
    "\n",
    "page10\n",
    "\n",
    "page10.content\n",
    "\n",
    "soup10 = BeautifulSoup(page10.content)\n",
    "\n",
    "soup10\n",
    "\n",
    "#Exracting house title\n",
    "h_title = soup10.find_all('h2', class_=\"heading-6 flex items-center font-semi-bold m-0\")\n",
    "\n",
    "h_title\n",
    "\n",
    "house_title = []\n",
    "\n",
    "for ht in h_title:\n",
    "    house_title.append(ht.text)\n",
    "    \n",
    "house_title\n",
    "\n",
    "len (house_title)\n",
    "\n",
    "\n",
    "#Extracting location\n",
    "loc = soup10.find_all('div', class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\")\n",
    "\n",
    "loc\n",
    "\n",
    "location = []\n",
    "\n",
    "for lc in loc:\n",
    "    location.append(lc.text)\n",
    "    \n",
    "location\n",
    "\n",
    "len (location)\n",
    "\n",
    "\n",
    "#Extracting cost of the house\n",
    "cost = soup10.find_all('div', class_=\"font-semi-bold heading-6\")\n",
    "\n",
    "cost\n",
    "\n",
    "\n",
    "price = []\n",
    "\n",
    "for p in cost:\n",
    "    price.append(p.text)\n",
    "    \n",
    "price\n",
    "\n",
    "f_price = []\n",
    "area = []\n",
    "\n",
    "for pr in range(0,len(price)):\n",
    "    \n",
    "    if pr%3:\n",
    "        f_price.append(price[pr])\n",
    "    else:\n",
    "        area.append(price[pr])\n",
    "        \n",
    "        \n",
    "#Printing build up area of the house\n",
    "area\n",
    "\n",
    "\n",
    "\n",
    "#Printing Prices and emi of the house\n",
    "f_price\n",
    "\n",
    "\n",
    "#Seperating EMI and price of the houses\n",
    "\n",
    "total_price = []\n",
    "emi = []\n",
    "for pt in range(0, len(f_price)):\n",
    "    if pt%2:\n",
    "        total_price.append(f_price[pt])\n",
    "    else:\n",
    "        emi.append(f_price[pt])\n",
    "        \n",
    "#Printing total price of the house\n",
    "total_price\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Printing EMIs of the house\n",
    "emi\n",
    "\n",
    "\n",
    "\n",
    "print(len(house_title), len(location), len(area), len(total_price), len(emi))\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "House_details = pd.DataFrame({})\n",
    "\n",
    "House_details['House Title'] = house_title\n",
    "House_details['Location'] = location\n",
    "House_details['Area'] = area\n",
    "House_details['Monthly EMI'] = emi\n",
    "House_details['Total Price'] = total_price\n",
    "\n",
    "\n",
    "House_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3162e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8622f107",
   "metadata": {},
   "source": [
    "Que 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9301acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.dineout.co.in/delhi-restaurants/buffet-special\"\n",
    "\n",
    "page=requests.get(url)\n",
    "\n",
    "page.content\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "Restaurant_Name=[]\n",
    "Price_and_Cuisine=[]\n",
    "Location=[]\n",
    "Ratings=[]\n",
    "Image_Url=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    " Restaurant_Name.append(i.text)\n",
    "Restaurant_Name\n",
    "\n",
    "\n",
    "Price_and_Cuisine=[]\n",
    "for i in soup.find_all('div',class_=\"detail-info\"):\n",
    " Price_and_Cuisine.append(i.text.replace('₹',' '))\n",
    "Price_and_Cuisine\n",
    "\n",
    "\n",
    "Location=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    " Location.append(i.text)\n",
    "Location\n",
    "\n",
    "\n",
    "Ratings=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    " Ratings.append(i.text)\n",
    "Ratings\n",
    "\n",
    "\n",
    "Image_Url=[]\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    " Image_Url.append(i['data-src'])\n",
    "Image_Url\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Restaurant_Name']=Restaurant_Name\n",
    "data['Price_and_Cuisine']=Price_and_Cuisine\n",
    "data['Location']=Location\n",
    "data['Ratings']=Ratings\n",
    "data['Image_Url']=Image_Url\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109a899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2494530e",
   "metadata": {},
   "source": [
    "Que 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea535e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.bewakoof.com/women-tshirts?ga_q=tshirts\"\n",
    "\n",
    "page=requests.get(url)\n",
    "page.content\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "Product_Name=[]\n",
    "Price=[]\n",
    "Image_Url=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all('div',class_=\"productCardDetail\"):\n",
    " Product_Name.append(i.text)\n",
    "Product_Name\n",
    "\n",
    "\n",
    "Price=[]\n",
    "for i in soup.find_all('span',class_=\"discountedPriceText\"):\n",
    " Price.append(i.text)\n",
    "Price\n",
    "\n",
    "\n",
    "Image_Url=[]\n",
    "for i in soup.find_all('img',class_=\"productImgTag\"):\n",
    " Image_Url.append(i['src'])\n",
    "Image_Url\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Product_Name']=Product_Name\n",
    "df['Price']=Price\n",
    "df['Image_Url']=Image_Url\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf4e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e2f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f6c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191e0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8c503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
